name: Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    runs-on: macos-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12', '3.x']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Print hardware info
      run: |
        echo "=== Hardware Information ==="
        sysctl -n machdep.cpu.brand_string
        system_profiler SPHardwareDataType | grep "Chip\|Model Name\|Total Number of Cores"
        echo "==========================="
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run tests with pytest
      env:
        PYTHONPATH: ${{ github.workspace }}/src
      run: |
        pytest tests/ -v --tb=short
    
    - name: Test basic example
      env:
        PYTHONPATH: ${{ github.workspace }}/src
      run: |
        python << 'EOF'
        import mlx.core as mx
        from bandit_sim import BanditEnvironment, ThompsonSampling, BanditSimulation, SimulationConfig
        
        env = BanditEnvironment.from_parameters(
            bernoulli_probs=[0.1, 0.5, 0.3, 0.7, 0.2]
        )
        
        algorithm = ThompsonSampling(num_arms=5, alpha=1.0, beta=1.0)
        
        config = SimulationConfig(horizon=100, runs=10)
        simulation = BanditSimulation(env, algorithm, config)
        results = simulation.run(mx.random.key(42))
        
        # Average across runs for final cumulative values
        avg_reward = float(mx.mean(results.cumulative_rewards[:, -1]))
        avg_regret = float(mx.mean(results.cumulative_regret[:, -1]))
        
        print(f"Average total reward (across {config.runs} runs): {avg_reward:.2f}")
        print(f"Average total regret (across {config.runs} runs): {avg_regret:.2f}")
        print("Basic example test passed!")
        EOF
    
    - name: Run demo script
      env:
        PYTHONPATH: ${{ github.workspace }}/src
      run: |
        python demo.py
    
    - name: Test notebooks
      env:
        PYTHONPATH: ${{ github.workspace }}/src
      run: |
        pip install jupyter
        jupyter nbconvert --execute --to notebook --inplace notebooks/introduction.ipynb
        jupyter nbconvert --execute --to notebook --inplace notebooks/clinical_trial_example.ipynb
    
    - name: Set artifact name
      id: artifact
      run: |
        VERSION="${{ matrix.python-version }}"
        SAFE_VERSION="${VERSION//./}"
        echo "name=demo-outputs-python-${SAFE_VERSION}" >> $GITHUB_OUTPUT
    
    - name: Upload demo outputs
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ${{ steps.artifact.outputs.name }}
        path: |
          easy_scenario.png
          hard_scenario.png
        retention-days: 14
